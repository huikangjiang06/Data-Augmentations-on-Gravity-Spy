{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1542137-0b2f-456a-8919-0f66f7dd02b2",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4936e8-117a-4732-8200-5c852c9bf172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee7e483-9ea7-4306-950a-ec94ffb8936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_sample(location):\n",
    "    x = np.load(location)\n",
    "    x = rescale(x, 0.55, multichannel=False, anti_aliasing=True, mode='reflect')\n",
    "    x = torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "def load_html_sample(url):\n",
    "    original_photo=requests.get(url)\n",
    "    with Image.open(BytesIO(original_photo.content)) as img:\n",
    "        data_img=np.array(img)\n",
    "    return data_img\n",
    "\n",
    "def img_cut(data):\n",
    "    \n",
    "    top_left_vertical = 60\n",
    "    top_left_horizontal = 100\n",
    "    height = 480\n",
    "    width = 575\n",
    "\n",
    "    if isinstance(data, PIL.Image.Image):\n",
    "        numpydata=np.arrary(data)\n",
    "        processed = Image.fromarray(numpydata[top_left_vertical:top_left_vertical+height, top_left_horizontal:top_left_horizontal+width])\n",
    "    if isinstance(data, np.ndarray):\n",
    "        processed = data[top_left_vertical:top_left_vertical+height, top_left_horizontal:top_left_horizontal+width]\n",
    "    return processed\n",
    "\n",
    "def gray_url(url):\n",
    "    img=load_html(url)\n",
    "    img=img_cut(img)\n",
    "    r, g, b = img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "def gray_scale(img):\n",
    "    r, g, b = img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "def normalize_array(img_array):\n",
    "    tensor = torch.from_numpy(img_array).permute(2, 0, 1).float() / 255.0\n",
    "    normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    normalized_tensor = normalize(tensor)\n",
    "    normalized_array = normalized_tensor.permute(1, 2, 0).numpy()\n",
    "    return normalized_array\n",
    "\n",
    "def normalize_2d_array(arr):\n",
    "\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "\n",
    "    normalized_arr = (arr - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db64d747-5aaf-4973-be28-fe40dabc4a92",
   "metadata": {},
   "source": [
    "# Augmentation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f81571-7e22-4f7a-bca3-8f4936183ef7",
   "metadata": {},
   "source": [
    "List of Over Sampling Methods:\n",
    "I. Geometric Augmentation\n",
    "1. Random Crop\n",
    "2. Artificial Noising\n",
    "3. Lateral Inversion\n",
    "4. Horizontal Inversion\n",
    "\n",
    "II. Photometic Augmentation \n",
    "1. Image Blurring\n",
    "\n",
    "III. Kernal \n",
    "\n",
    "IV. Mixing\n",
    "\n",
    "V. Random Earasing\n",
    "\n",
    "VI. SMOTE\n",
    "\n",
    "Down Sampling Methods:\n",
    "I. Random Down Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85400310-831c-47a5-b62e-b6d92b03037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "### 看看之后dataset用什么数据类型然后来调整这段代码\n",
    "def batch_augmentation(dataset: list, method):\n",
    "    augmented_set=[]\n",
    "    images = [x[0] for x in dataset]\n",
    "    for sample in tqdm(images):\n",
    "        sample=method(sample)\n",
    "        augmented_set.append(sample)\n",
    "    return augmented_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92285868-9c4b-4f0c-b68f-234eb1c86273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def random_crop(image, crop_size=(360,460)):\n",
    "    img_size = image.shape\n",
    "    channel_0, channel_1, channel_2 = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "    idx_row = random.randint(0, img_size[0] - crop_size[0])\n",
    "    idx_column = random.randint(0, img_size[0] - crop_size[0])\n",
    "    channel_0 = channel_0[idx_row:idx_row + crop_size[0], \n",
    "                          idx_column:idx_column + crop_size[1]]\n",
    "    channel_1 = channel_1[idx_row:idx_row + crop_size[0], \n",
    "                          idx_column:idx_column + crop_size[1]]\n",
    "    channel_2 = channel_2[idx_row:idx_row + crop_size[0], \n",
    "                          idx_column:idx_column + crop_size[1]]\n",
    "    image = np.dstack((channel_0, channel_1, channel_2))\n",
    "    image = cv2.resize(image, img_size)\n",
    "    return image\n",
    "\n",
    "def img_noising(image, noise_intensity=0.2):\n",
    "    img_shape=image.shape\n",
    "    noise_threshold = 1 - noise_intensity\n",
    "    channel_0, channel_1, channel_2 = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "\n",
    "    channel_0 = channel_0.reshape(1024)\n",
    "    channel_1 = channel_1.reshape(1024)\n",
    "    channel_2 = channel_2.reshape(1024)\n",
    "\n",
    "    noise_0 = np.zeros(1024, dtype='uint8')\n",
    "    noise_1 = np.zeros(1024, dtype='uint8')\n",
    "    noise_2 = np.zeros(1024, dtype='uint8')\n",
    "\n",
    "    for idx in range(1024):\n",
    "      regulator = round(random.random(), 1)\n",
    "      if regulator > noise_threshold:\n",
    "        noise_0[idx] = 255\n",
    "        noise_1[idx] = 255\n",
    "        noise_2[idx] = 255\n",
    "      elif regulator == noise_threshold:\n",
    "        noise_0[idx] = 0\n",
    "        noise_1[idx] = 0\n",
    "        noise_2[idx] = 0\n",
    "      else:\n",
    "        noise_0[idx] = channel_0[idx]\n",
    "        noise_1[idx] = channel_1[idx]\n",
    "        noise_2[idx] = channel_2[idx]\n",
    "\n",
    "    noise_0 = noise_0.reshape(img_shape)\n",
    "    noise_1 = noise_1.reshape(img_shape)\n",
    "    noise_2 = noise_2.reshape(img_shape)\n",
    "\n",
    "    image = np.dstack((noise_0, noise_1, noise_2))\n",
    "    return image\n",
    "\n",
    "def horizontal_flip(image):\n",
    "    channel_0, channel_1, channel_2 = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "    channel_0 = channel_0[:, ::-1]\n",
    "    channel_1 = channel_1[:, ::-1]\n",
    "    channel_2 = channel_2[:, ::-1]\n",
    "    image = np.dstack((channel_0, channel_1, channel_2))\n",
    "    return image\n",
    "\n",
    "def vertical_flip(image):\n",
    "    channel_0, channel_1, channel_2 = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "    channel_0 = channel_0[::-1, :]\n",
    "    channel_1 = channel_1[::-1, :]\n",
    "    channel_2 = channel_2[::-1, :]\n",
    "    image = np.dstack((channel_0, channel_1, channel_2))\n",
    "    return image\n",
    "\n",
    "def rotation(image,angle=90):\n",
    "    channel_0, channel_1, channel_2 = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "\n",
    "    if angle == 90:\n",
    "        channel_0 = np.rot90(channel_0)\n",
    "        channel_1 = np.rot90(channel_1)\n",
    "        channel_2 = np.rot90(channel_2)\n",
    "    elif angle == 180:\n",
    "        channel_0 = np.rot90(channel_0, 2)\n",
    "        channel_1 = np.rot90(channel_1, 2)\n",
    "        channel_2 = np.rot90(channel_2, 2)\n",
    "    elif angle == 270:\n",
    "        channel_0 = np.rot90(channel_0, 3)\n",
    "        channel_1 = np.rot90(channel_1, 3)\n",
    "        channel_2 = np.rot90(channel_2, 3)\n",
    "\n",
    "    image = np.dstack((channel_0, channel_1, channel_2))\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1161ea2a-9e12-4c23-95d9-fbca591ddb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, padding=2):\n",
    "    \n",
    "    channel_0, channel_1, channel_2 = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "\n",
    "    padded_0 = np.zeros((image.shape[0] + padding*2, \n",
    "                         image.shape[1] + padding*2), dtype='uint8')\n",
    "    padded_1 = np.zeros((image.shape[0] + padding*2, \n",
    "                         image.shape[1] + padding*2), dtype='uint8')\n",
    "    padded_2 = np.zeros((image.shape[0] + padding*2, \n",
    "                         image.shape[1] + padding*2), dtype='uint8')\n",
    "    \n",
    "    #  inserting image into zero array\n",
    "    padded_0[int(padding):-int(padding), \n",
    "             int(padding):-int(padding)] = channel_0\n",
    "    padded_1[int(padding):-int(padding), \n",
    "             int(padding):-int(padding)] = channel_1\n",
    "    padded_2[int(padding):-int(padding), \n",
    "             int(padding):-int(padding)] = channel_2\n",
    "\n",
    "    padded = np.dstack((padded_0, padded_1, padded_2))\n",
    "    \n",
    "    return padded\n",
    "\n",
    "def blur_image(image, kernel_size=5, padding=2):\n",
    "\n",
    "    gauss_5 = np.array([[1, 4, 7, 4, 1],\n",
    "                     [4, 16, 26, 16, 4],\n",
    "                     [7, 26, 41, 26, 7],\n",
    "                     [4, 16, 26, 16, 4],\n",
    "                     [1, 4, 7, 4, 1]])\n",
    "    \n",
    "    filter = 1/273 * gauss_5\n",
    "\n",
    "    if padding>0:\n",
    "      image = pad_image(image,padding=padding)\n",
    "    else:\n",
    "      image = image\n",
    "\n",
    "    channel_0, channel_1, channel_2 = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "\n",
    "    blurred_0 = np.zeros(((image.shape[0] - kernel_size) + 1, \n",
    "                          (image.shape[1] - kernel_size) + 1), dtype='uint8')\n",
    "    blurred_1 = np.zeros(((image.shape[0] - kernel_size) + 1, \n",
    "                          (image.shape[1] - kernel_size) + 1), dtype='uint8')\n",
    "    blurred_2 = np.zeros(((image.shape[0] - kernel_size) + 1, \n",
    "                          (image.shape[1] - kernel_size) + 1), dtype='uint8')\n",
    "    \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            try:\n",
    "                blurred_0[i,j] = (channel_0[i:(i+kernel_size), j:(j+kernel_size)] * filter).sum()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            try:\n",
    "                blurred_1[i,j] = (channel_1[i:(i+kernel_size), j:(j+kernel_size)] * filter).sum()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            try:\n",
    "                blurred_2[i,j] = (channel_2[i:(i+kernel_size), j:(j+kernel_size)] * filter).sum()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    blurred = np.dstack((blurred_0, blurred_1, blurred_2))\n",
    "    \n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27550a72-873b-4375-a1b2-3fb067b903c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87b59c68-beff-4169-9cae-96b8dc7f03dd",
   "metadata": {},
   "source": [
    "# Helper Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f4a531-0125-4b87-b1d8-e5436e0061e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, loss_func, device=None): \n",
    "    net.eval()\n",
    "    metric = Accumulator(3)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device).to(torch.float)\n",
    "            y = y.to(device).to(torch.long)\n",
    "            y_hat = net(X)\n",
    "            loss = loss_func(y_hat, y)\n",
    "            metric.add(accuracy(y_hat, y), y.numel(), loss.sum())\n",
    "    return metric[0] / metric[1], metric[2] / metric[1]\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    _, labels = torch.max(labels, dim=1)\n",
    "    return (preds == labels).sum().item() / len(preds)\n",
    "\n",
    "\n",
    "def save_model(epoch, model, optimizer, scheduler, checkpoint_dir, train_loss_history, filename):\n",
    "\n",
    "    p = Path(checkpoint_dir)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    assert '.pt' in filename\n",
    "    for f in [f for f in os.listdir(p) if '.pt' in f]:\n",
    "        os.remove(p / f)\n",
    "\n",
    "    np.save(p / 'train_loss_history_cnn', train_loss_history)\n",
    "\n",
    "    output = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'optimizer_type': type(optimizer).__name__,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "\n",
    "    if scheduler is not None:\n",
    "        output['scheduler_state_dict'] = scheduler.state_dict()\n",
    "        output['scheduler_type'] = type(scheduler).__name__\n",
    "        \n",
    "    torch.save(output, p / filename)\n",
    "\n",
    "\n",
    "def load_net(checkpoint_dir=None):\n",
    "    \n",
    "    net = MyNet()\n",
    "    \n",
    "    if (checkpoint_dir is not None) and (Path(checkpoint_dir).is_dir()):\n",
    "        p = Path(checkpoint_dir)\n",
    "        files = [f for f in os.listdir(p) if '.pt' in f]\n",
    "        \n",
    "        if (files != []) and (len(files) == 1):\n",
    "            checkpoint = torch.load(p / files[0])\n",
    "            net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        epoch = checkpoint['epoch']\n",
    "        \n",
    "        train_loss_history = np.load(p / 'train_loss_history_cnn.npy').tolist()\n",
    "        \n",
    "        return net, epoch, train_loss_history\n",
    "        \n",
    "    else:\n",
    "        return net, 0, []\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def load_model(checkpointdir):\n",
    "\n",
    "    net = MyNet()\n",
    "    \n",
    "    if checkpointdir is not None:\n",
    "        p = Path(checkpointdir)\n",
    "        if not p.is_dir():\n",
    "            print('Checkpoint Error')\n",
    "            return None\n",
    "    \n",
    "        files = [f for f in os.listdir(p) if f.endswith('.pt')]\n",
    "        if not files:\n",
    "            print('No model file found')\n",
    "            return None\n",
    "    \n",
    "        checkpoint_path = p / files[0]\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "        optimizer_type = checkpoint.get('optimizer_type')\n",
    "        if optimizer_type:\n",
    "            optimizer = getattr(optim, optimizer_type)(net.parameters())\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        else:\n",
    "            optimizer = None\n",
    "    \n",
    "        scheduler_type = checkpoint.get('scheduler_type')\n",
    "        if scheduler_type:\n",
    "            scheduler = getattr(optim.lr_scheduler, scheduler_type)(optimizer)\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        else:\n",
    "            scheduler = None\n",
    "    \n",
    "        epoch = checkpoint['epoch']\n",
    "        train_loss_history = checkpoint['train_loss_history']\n",
    "    \n",
    "        print('Load Successful')\n",
    "        \n",
    "        return net, optimizer, scheduler, epoch, train_loss_history\n",
    "\n",
    "    else:\n",
    "        return net, 0, []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a8f4e-2eb9-4a40-a603-17336613ef8a",
   "metadata": {},
   "source": [
    "# Data Loader Customized for Gravity Spy and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4b288-9644-4184-a4b6-3439759c607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PyTorch defines the class Dataset and DataLoader in a way that loading data can be easily customized. We make use of this advantage.\n",
    "\n",
    "The Gravity Spy dataset is recorded a number of csv files, in which accountst he URLs to each time-frequency spectrogram. The URLS \n",
    "alone takes up 1.1 G of memory. The images, original and later augmented, will take up more. \n",
    "\n",
    "We customize our Dataset and DataLoader class so that we can perform augmentations easily while save memory spaces. \n",
    "'''\n",
    "\n",
    "'''\n",
    "Keep the data as DataFrame and images and numpy array before inputting the model\n",
    "'''\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GS_Aug_Dataset(Dataset):\n",
    "    def _init_(self,x,num_aug,list_aug):\n",
    "        '''\n",
    "        x: DataFrame\n",
    "        Desired data structure: {index, label, url1, url2, url3, ulr4} \n",
    "        \n",
    "        After agumentation: DataFrame\n",
    "        Desired data structure: {index, label, [index to original image, [0,0,0,...,0] one_hot indication of augmentation type]}\n",
    "\n",
    "        list_aug: all needed augmentation methods, its elements are \"function\" types\n",
    "        '''\n",
    "\n",
    "        self.augmented_x = x\n",
    "        self.original_length = x.shape[0]\n",
    "        self.num_aug = num_aug\n",
    "        self.list_aug = list_aug\n",
    "\n",
    "    #Dataset 和 DataLoader之间的协议是Dataset的_getitem_函数要返回 x, y\n",
    "    def _getitem_(self,idx):\n",
    "        \n",
    "        content = self.augmented_x.iloc[idx,1]\n",
    "        original_index = -1\n",
    "        \n",
    "        if isinstance(content, str):\n",
    "            original_index = idx\n",
    "            \n",
    "        elif instance(content,list):\n",
    "            aug_list = [0] * num_aug\n",
    "            while True:\n",
    "                origianl_index = content[0]\n",
    "                content = self.augmented_x.iloc[original_index,1]\n",
    "                if isinstance(content,str):\n",
    "                    break\n",
    "                else:\n",
    "                    aug_list = [a + b for a, b in zip(aug_list, content[1])]\n",
    "        \n",
    "        url2 = self.augmented_x.iloc[original_index,2]\n",
    "        url3 = self.augmented_x.iloc[original_index,3]\n",
    "        url4 = self.augmented_x.iloc[original_index,4]\n",
    "\n",
    "        for url in [content,url2,url3,url4]:\n",
    "            url = gray_scale(img_cut(load_html_sample(url)))\n",
    "            for i, method in enumerate(aug_list):\n",
    "                if aug_list[i] == 1:\n",
    "                    url = list_aug[i](url)\n",
    "\n",
    "        return [content,url2,url3,url4], self.augmented_x.iloc[original_index,1]\n",
    "    \n",
    "    def _len_(self):\n",
    "        return len(self.augmented_x)\n",
    "\n",
    "    def _augment_(self, method:list, aug_on_aug = False,labels: list = ['All']):\n",
    "        '''\n",
    "        method: same as list_aug, a list of functions\n",
    "        aug_on_aug: whether to do augmentation on what is already an augmentation\n",
    "        labels: labels to which the augmentation is effected\n",
    "        '''\n",
    "\n",
    "        if aug_on_aug == False:\n",
    "            if labels[0] == 'All':\n",
    "                to_aug = self.augmented_x[0:self.original_length+1, 0:2]\n",
    "                \n",
    "            else:\n",
    "                origianl_data = self.augmented_x[0:self.original_length+1]\n",
    "                to_aug = pd.DataFrame()\n",
    "                for label in labels:\n",
    "                    original_data = original_data[:,0:2]\n",
    "                    temp = original_data[self.x.iloc[:, 0] == label]\n",
    "                    to_aug = pd.concat([to_aug, temp])\n",
    "        \n",
    "        elif aug_on_aug == True:\n",
    "            if labels[0] == 'All':\n",
    "                to_aug = self.augmented_x[:,0:2]\n",
    "            \n",
    "            else:\n",
    "                to_aug = pd.DataFrame()\n",
    "                for label in labels:\n",
    "                    temp = self.augmented_x[self.x.iloc[:, 0] == label]\n",
    "                    temp = temp[:,0:2]\n",
    "                    to_aug = pd.concat([to_aug, temp])\n",
    "\n",
    "        for method in methods:\n",
    "                \n",
    "            one_hot = [0] * len(list_aug)\n",
    "            one_hot[self.list_aug.index(method)] = 1\n",
    "        \n",
    "            for i in range (0,to_aug.shape[0]+1):\n",
    "                to_aug.iloc[i,1] = [int(to_aug.iloc[i].name),one_hot]\n",
    "        \n",
    "            self.augmented_x = pd.concat([self.augmented_x, to_aug], ignore_index = True)\n",
    "\n",
    "class GS_Simple_Dataset1(Dataset):\n",
    "    def _init_(self,x):\n",
    "        '''\n",
    "        x: DataFrame\n",
    "        Desired data structure: {index, label, url1, url2, url3, ulr4} \n",
    "        '''\n",
    "        self.x = x\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def _gititem_(self,idx):\n",
    "        url1 = self.x.iloc[idx,1]\n",
    "        url2 = self.x.iloc[idx,2]\n",
    "        url3 = self.x.iloc[idx,3]\n",
    "        url4 = self.x.iloc[idx,4]\n",
    "\n",
    "        for url in [url1, url2, url3, url4]:\n",
    "            url = gray_scale(img_cut(load_html_sample(url)))\n",
    "\n",
    "        top_row = np.concatenate((url1, url2), axis=1)\n",
    "        bottom_row = np.concatenate((url3, url4), axis=1)\n",
    "        final_image = np.concatenate((top_row, bottom_row), axis=0)\n",
    "\n",
    "        return final_image, self.x.iloc[idx,0]\n",
    "\n",
    "\n",
    "class GS_Smple_Dataset2(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label_col, url_cols, transform=None, max_workers=4):\n",
    "        self.data = data.reset_index(drop=True)  # 重置索引\n",
    "        self.label_col = label_col\n",
    "        self.url_cols = url_cols\n",
    "        self.transform = transform\n",
    "        self.max_workers = max_workers\n",
    "        self.executor = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        self.lock = threading.Lock()\n",
    "        self.image_cache = {}  # 缓存加载的图像\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. 获取基础数据\n",
    "        with self.lock:\n",
    "            label = self.data.loc[idx, self.label_col]\n",
    "            urls = [self.data.loc[idx, col] for col in self.url_cols]\n",
    "\n",
    "        # 2. 加载并处理图像（多线程加速）\n",
    "        images = []\n",
    "        with self.lock:\n",
    "            for url in urls:\n",
    "                if url in self.image_cache:\n",
    "                    images.append(self.image_cache[url])\n",
    "                    continue\n",
    "                # 下载并处理图像\n",
    "                try:\n",
    "                    response = requests.get(url, timeout=10)\n",
    "                    img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "                    if self.transform:\n",
    "                        img = self.transform(img)\n",
    "                    images.append(img)\n",
    "                    self.image_cache[url] = img  # 缓存结果\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {url}: {str(e)}\")\n",
    "                    lol = next(iter(self.image_cache.values()))\n",
    "                    lol = np.array(lol)\n",
    "                    lol = torch.from_numpy(lol)\n",
    "                    images.append(torch.zeros_like(lol))  # 填充空值\n",
    "\n",
    "        # 3. 图像拼接\n",
    "        img1, img2, img3, img4 = images\n",
    "\n",
    "        img1 = np.array(img1)\n",
    "        img1 = torch.from_numpy(img1)\n",
    "        img2 = np.array(img2)\n",
    "        img2 = torch.from_numpy(img2)\n",
    "        img3 = np.array(img3)\n",
    "        img3 = torch.from_numpy(img3)\n",
    "        img4 = np.array(img4)\n",
    "        img4 = torch.from_numpy(img4)\n",
    "\n",
    "        top_row = torch.cat((img1, img2), dim=2)  # 水平拼接\n",
    "        bottom_row = torch.cat((img3, img4), dim=2)\n",
    "        final_image = torch.cat((top_row, bottom_row), dim=1)  # 垂直拼接\n",
    "\n",
    "        # 4. 数据增强\n",
    "        if self.transform:\n",
    "            final_image = self.transform(final_image)\n",
    "\n",
    "        return final_image, label\n",
    "\n",
    "class GS_Simple_Dataset3(Dataset):\n",
    "    def __init__(self, x: pd.DataFrame):\n",
    "        # 强制用 0..N-1 做行索引，方便 .iloc 访问\n",
    "        self.x = x.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 用 iloc 取到第 idx 行\n",
    "        row = self.x.iloc[idx]\n",
    "\n",
    "        # 确保列名一致：'url1','url2','url3','url4'\n",
    "        def is_valid_url(url):\n",
    "            try:\n",
    "                response = requests.head(url, timeout=5)\n",
    "                return response.status_code == 200\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        urls = [row[f'url{i}'] for i in range(1, 5)]\n",
    "        valid_urls = [url for url in urls if is_valid_url(url)]\n",
    "\n",
    "        while len(valid_urls) < 4 and valid_urls:\n",
    "            valid_urls.extend(valid_urls[:4-len(valid_urls)])\n",
    "\n",
    "        imgs = []\n",
    "        for i in range(4):\n",
    "            if i < len(valid_urls):\n",
    "                url = valid_urls[i]\n",
    "                html = load_html_sample(url)\n",
    "                cut = img_cut(html)\n",
    "                gray = gray_scale(cut)\n",
    "                imgs.append(gray)\n",
    "            else:\n",
    "                imgs.append(None)\n",
    "\n",
    "        # 拼接四张图：左右拼 → 上下拼\n",
    "        top    = np.concatenate((imgs[0], imgs[1]), axis=1)\n",
    "        bottom = np.concatenate((imgs[2], imgs[3]), axis=1)\n",
    "        final  = np.concatenate((top, bottom), axis=0)\n",
    "\n",
    "        # 转 torch tensor，必要时指定 dtype、加上 channel 维度\n",
    "        tensor = torch.from_numpy(final).float().unsqueeze(0)  # e.g. [1,H,W]\n",
    "\n",
    "        # 同理取 label\n",
    "        label = row['ml_label']\n",
    "        # 如果你要做分类，通常还要转成 LongTensor：\n",
    "        # label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return tensor, label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
